#' Setup the ColabNet database for the current session
#'
#' @param path Path to a database. If DB does not exist it will be created from the schema
#' @param schema An SQLite database schema (.sql file)
#' @param checkSchema (Default, FALSE) Check the schema of an existing database against the reference
#' @param returnConn (Default, FALSE) By default this function will save the connection to the database
#' internally to be used by other functions. If set to TRUE, a connection object is returned
#' and needs to be closed manually using dbDisconnect()
#' @param setDBSession (Default, FALSE) Set the dbInfo for the global session so it does not
#' have to be provided for all other DB functions. Don't use this in Shiny!
#'
#' @import RSQLite
#' @importFrom stringr str_remove
#'
#' @return A list with 4 elements
#' - success: T/F whether the connection to the database was succesful
#' - statusCode: 0,1,2 are success, others are failures
#' - msg: The message for each status code
#' - conn: a connection object if returnConn = T
#' @export
#'
dbSetup <- function(
  path,
  schema,
  checkSchema = F,
  returnConn = F,
  setDBSession = F
) {
  # Path check
  if (
    missing(path) ||
      !dir.exists(dirname(path)) ||
      !str_detect(basename(path), "^[\\w-]+\\.db$")
  ) {
    return(list(
      success = F,
      statusCode = 4,
      msg = paste("Provide a valid path to a database file ending in .db"),
      conn = NULL
    ))
  }

  # Start with empty connection
  myConn <- NULL
  # Get the reference schema
  sqlFile <- readLines(schema) |>
    paste(collapse = "") |>
    str_remove(";\\s*$")

  if (!file.exists(path)) {
    # Create a new database
    tables <- strsplit(sqlFile, ";") |> unlist()
    myConn <- dbConnect(SQLite(), path)
    q <- sapply(tables, function(sql) {
      q <- dbExecute(myConn, sql)
    })

    msg <- "A new database was created"
    statusCode <- 0
  } else if (checkSchema) {
    myConn <- dbConnect(SQLite(), path)
    # Extract the schema from the database to compare to the reference
    dbSchema <- dbGetQuery(
      myConn,
      paste(
        'SELECT sql FROM sqlite_master WHERE type IN ("table", "index")',
        ' AND "sql" NOT NULL AND name != \'sqlite_sequence\''
      )
    ) |>
      unlist() |>
      paste(collapse = ";")

    # Remove any INSERT statements as they are not part of the schema
    sqlFile <- str_remove(sqlFile, ";INSERT.*")

    if (dbSchema != sqlFile) {
      msg <- paste(
        sprintf("The schema of %s is not valid.\n", path),
        "- Create a blank database by providing a new path\n",
        "- Edit the schema of the existing database to match the requirements"
      )
      statusCode <- 3
    } else {
      msg <- "Successful connection to existing database; schema validated"
      statusCode <- 2
    }
  } else {
    myConn <- dbConnect(SQLite(), path)
    msg <- "Successful connection to existing database; schema not validated"
    statusCode <- 1
  }

  # When not to return the connection
  if ((!is.null(myConn) & !returnConn) | statusCode == 3) {
    dbDisconnect(myConn)
    myConn <- NULL
  }

  # Save the connection info for the session
  if (setDBSession) {
    options(dbPath = path)
  }

  return(list(
    success = statusCode %in% c(0, 1, 2),
    statusCode = statusCode,
    msg = msg,
    conn = myConn
  ))
}

#' Get a ColabNet database connection
#'
#' @param dbInfo (optional if dbSetup() has been run) Path to the ColabNet database
#' or existing connection. If the dbSetup() has been run the assigned database will be used
#'
#' @import RSQLite
#'
#' @return Connection to the ColabNet database
#' @export
#'
dbGetConn <- function(dbInfo) {
  if (missing(dbInfo)) {
    # getOption("dbInfo") has  database info in global environment
    if (is.null(getOption("dbInfo", default = NULL))) {
      stop("There is no database set up, please run dbSetup() first")
    }

    conn <- dbConnect(SQLite(), getOption("dbInfo"))
    # Keep track of whether an existing connection was passed into the function
    attr(conn, "existing") <- F
  } else if (inherits(dbInfo, "DBIConnection")) {
    conn <- dbInfo
    attr(conn, "existing") <- T
  } else if ("Pool" %in% class(dbInfo)) {
    conn <- pool::localCheckout(dbInfo)
    attr(conn, "existing") <- F
  } else {
    conn <- dbSetup(dbInfo, returnConn = T)
    attr(conn, "existing") <- F
  }

  # Make sure that foreign key constraints and cascading are enforced
  q <- dbExecute(conn, "PRAGMA foreign_keys = ON")

  return(conn)
}

#' Add authors to the database
#'
#' @param authors The coAuthors data frame generated by ncbi_authorPublications
#' @param dbInfo (optional if dbSetup() has been run) Path to the ColabNet database
#'  or existing connection
#'
#' @import RSQLite
#' @import dplyr
#'
#' @return Data frame with new, updated and existing author info
#' @export
#'
dbAddAuthors <- function(authors, dbInfo) {
  tryCatch(
    {
      conn <- dbGetConn(dbInfo)

      if (sqliteIsTransacting(conn)) {
        endTransaction <- F
      } else {
        dbBegin(conn)
        endTransaction <- T
      }

      # Get all distinct author names, but assume same author is last name and initials are the same
      authors <- authors |>
        select(
          lastName,
          firstName,
          initials,
          collectiveName,
          tempId,
          def = default
        ) |>
        distinct()

      authors <- authors |>
        left_join(
          tbl(conn, "authorName"),
          by = c("lastName", "firstName", "initials", "collectiveName"),
          copy = TRUE
        ) |>
        collect()

      # Check which authors already exist in the DB (nothing to do)
      existing <- authors |>
        group_by(tempId) |>
        filter(!is.na(anID)) |>
        ungroup() |>
        mutate(status = "existing")

      # Check authors that are already in the DB, but an alternative version of the name popped up
      updated <- authors |>
        group_by(tempId) |>
        filter(!sum(is.na(anID)) %in% c(0, n())) |>
        ungroup()

      # Add those alternative names to the DB with same author ID
      if (nrow(updated) > 0) {
        updated <- updated |>
          group_by(tempId) |>
          mutate(auID = min(auID, na.rm = T)) |>
          ungroup() |>
          filter(is.na(anID))
        updated <- dbGetQuery(
          conn,
          "INSERT INTO authorName(auID,lastName,firstName,initials,collectiveName)
        VALUES (?,?,?,?,?) RETURNING *",
          params = list(
            updated$auID,
            updated$lastName,
            updated$firstName,
            updated$initials,
            updated$collectiveName
          )
        ) |>
          mutate(status = "updated")

        q <- dbExecute(
          conn,
          sprintf(
            "UPDATE author SET modified = '%s' WHERE auID IN (%s)",
            timeStamp(),
            paste(unique(updated$auID), collapse = ",")
          )
        )
      }

      # Add authors who are not yet in the DB
      new <- authors |>
        group_by(tempId) |>
        filter(all(is.na(anID))) |>
        ungroup() |>
        select(-auID)

      if (nrow(new) > 0) {
        # Create new author IDs
        auID <- dbGetQuery(
          conn,
          "INSERT INTO author(modified) VALUES (?) RETURNING auID",
          params = list(rep(timeStamp(), new$tempId |> n_distinct()))
        )
        auID$tempId <- unique(new$tempId)
        new <- new |> left_join(auID, by = "tempId")

        # Add author names
        new <- dbGetQuery(
          conn,
          "INSERT INTO authorName(auID,\"default\",lastName,firstName,initials,collectiveName)
        VALUES (?,?,?,?,?,?) RETURNING *",
          params = list(
            new$auID,
            new$def,
            new$lastName,
            new$firstName,
            new$initials,
            new$collectiveName
          )
        ) |>
          mutate(status = "new")
      }

      if (endTransaction) {
        dbCommit(conn)

        if (!attr(conn, "existing")) {
          dbDisconnect(conn)
        }
      }

      return(bind_rows(new, updated, existing) |> select(-tempId))
    },
    error = function(e) {
      # If an error occurs, rollback the current transaction
      dbRollback(conn)
      if (!attr(conn, "existing")) {
        dbDisconnect(conn)
      }
      stop(e)
    }
  )
}

#' Remove authors and their articles from the database
#'
#' @param auIDs auIDs to remove. Co-authors who are not and authorOfInterest and
#' do not appear in other non-removed articles, are removed too
#' @param dbInfo (optional if dbSetup() has been run) Path to the ColabNet database
#'  or existing connection
#'
#' @import dplyr
#'
#' @return data frame with all auID and arID that were removed
#' @export
#'
dbDeleteAuthors <- function(auIDs, dbInfo) {
  tryCatch(
    {
      conn <- dbGetConn(dbInfo)

      if (sqliteIsTransacting(conn)) {
        endTransaction <- F
      } else {
        dbBegin(conn)
        endTransaction <- T
      }

      # Get all articles and authors to remove
      toRemove <- tbl(conn, "coAuthor") |>
        select(arID, auID1 = auID) |>
        left_join(
          tbl(conn, "author") |> select(auID1 = auID, authorOfInterest),
          by = "auID1"
        ) |>
        left_join(
          tbl(conn, "coAuthor") |> select(arID, auID2 = auID),
          by = "arID"
        ) |>
        filter(
          auID2 %in% local(auIDs),
          auID1 %in% local(auIDs) | authorOfInterest == 0
        ) |>
        select(auID = auID1, arID) |>
        collect()

      # Make sure not to remove co-authors who apprear in articles that are not being deleted
      toKeep <- tbl(conn, "coAuthor") |>
        filter(
          !arID %in% local(toRemove$arID),
          auID %in% local(toRemove$auID)
        ) |>
        pull(auID) |>
        unique()

      toRemove <- toRemove |> filter(!auID %in% toKeep)

      # Delete authors
      q <- dbExecute(
        conn,
        sprintf(
          "DELETE FROM author WHERE auID IN (%s)",
          paste(unique(toRemove$auID), collapse = ",")
        )
      )

      # Delete articles
      q <- dbExecute(
        conn,
        sprintf(
          "DELETE FROM article WHERE arID IN (%s)",
          paste(unique(toRemove$arID), collapse = ",")
        )
      )

      if (endTransaction) {
        dbCommit(conn)
        if (!attr(conn, "existing")) {
          dbDisconnect(conn)
        }
      }

      return(toRemove)
    },
    error = function(e) {
      # If an error occurs, rollback the current transaction
      dbRollback(conn)
      if (!attr(conn, "existing")) {
        dbDisconnect(conn)
      }
      stop(e)
    }
  )
}

#' Insert MeSH info into the ColabNet database
#'
#' @param values vector of MeSH values to search for
#' @param type The type needs to be 'meshui' (MeSH ui), 'treenum' (tree number) or 'uid' (MeSH Entrez uid)
#' @param dbInfo (optional if dbSetup() has been run) Path to the ColabNet database
#'  or existing connection
#'
#' @import dplyr
#'
#' @return data frame with all uid and meshui inserted into the database (including intermediate tree nodes)
#' @export
#'
dbAddMesh <- function(values, type, dbInfo) {
  tryCatch(
    {
      conn <- dbGetConn(dbInfo)

      if (sqliteIsTransacting(conn)) {
        endTransaction <- F
      } else {
        dbBegin(conn)
        endTransaction <- T
      }

      meshInfo <- ncbi_meshInfo(values, type)

      # Check with intermediate tree nodes (treenum) are missing to get to root
      missingNodes <- missingTreeNums(meshInfo$meshTree$treenum)

      # Check DB which missing treenums (intermediate nodes) are already in the DB
      knownTreenums <- tbl(conn, "meshTree") |>
        filter(treenum %in% local(missingNodes)) |>
        pull(treenum)

      # Get info on remaining missing nodes
      missingNodes <- setdiff(missingNodes, knownTreenums)

      # Iteratively add missing nodes
      #  Iteration needed because some IDs have multple treenums
      while (length(missingNodes) > 0) {
        # Seach NCBI and add results
        newNodes <- ncbi_meshInfo(missingNodes, type = "treenum")
        meshInfo$meshTerms <- rbind(meshInfo$meshTerms, newNodes$meshTerms)
        meshInfo$meshTree <- rbind(meshInfo$meshTree, newNodes$meshTree)

        # Again check if there are missing links in the new nodes
        missingNodes <- missingTreeNums(meshInfo$meshTree$treenum)
        knownTreenums <- c(
          knownTreenums,
          tbl(conn, "meshTree") |>
            filter(treenum %in% local(missingNodes)) |>
            pull(treenum)
        )

        missingNodes <- setdiff(missingNodes, knownTreenums)
      }

      toAdd <- setdiff(meshInfo$meshTree$treenum, knownTreenums)

      if (length(toAdd) > 0) {
        # Only add new tree data
        meshInfo$meshTree <- meshInfo$meshTree |> filter(treenum %in% toAdd)
        meshInfo$meshTerms <- meshInfo$meshTerms |>
          filter(meshui %in% meshInfo$meshTree$meshui)

        # Find new and existing
        meshLinks <- meshInfo$meshTree |>
          select(uid, meshui) |>
          distinct() |>
          mutate(uid = as.integer(uid))
        existing <- tbl(conn, "meshLink") |>
          filter(uid %in% local(meshLinks$uid)) |>
          select(uid, meshui) |>
          collect()
        new <- meshLinks |> filter(!uid %in% existing$uid)

        # Insert new MeSH links
        q <- dbExecute(
          conn,
          "INSERT INTO meshLink(uid, meshui) VALUES(?,?)",
          params = list(new$uid, new$meshui)
        )

        # Insert new MeSH Terms
        meshTerms <- meshInfo$meshTerms |>
          select(meshui, meshterm) |>
          distinct()
        meshTerms <- meshTerms |> filter(!meshui %in% existing$meshui)
        q <- dbExecute(
          conn,
          "INSERT INTO meshTerm(meshui, meshterm) VALUES(?,?)",
          params = list(meshTerms$meshui, meshTerms$meshterm)
        )

        # Insert new MeSH Tree branches
        meshTree <- meshInfo$meshTree |>
          select(uid, treenum) |>
          distinct()
        meshTree <- meshTree |> filter(!uid %in% existing$uid)
        q <- dbExecute(
          conn,
          "INSERT INTO meshTree(uid, treenum) VALUES(?,?)",
          params = list(meshTree$uid, meshTree$treenum)
        )
      }

      if (endTransaction) {
        dbCommit(conn)
        if (!attr(conn, "existing")) {
          dbDisconnect(conn)
        }
      }

      return(bind_rows(
        new |> mutate(status = "new"),
        existing |> mutate(status = "existing")
      ))
    },
    error = function(e) {
      # If an error occurs, rollback the current transaction
      dbRollback(conn)
      if (!attr(conn, "existing")) {
        dbDisconnect(conn)
      }
      stop(e)
    }
  )
}

#' Tell the colabNet app an update has been made and it needs to refresh
#'
#' @param action (Integer) The code of the action
#'  - 0 = new database init
#'  - 1 = add data
#'  - 2 = delete data
#' @param dbInfo (optional if dbSetup() has been run)
#'  Path to the ColabNet database or existing connection
#'
#' @import RSQLite
#'
#' @return Bool to indicate success
#' @export
#'
dbFlagUpdate <- function(action, dbInfo) {
  tryCatch(
    {
      action <- as.integer(action)

      if (!action %in% 1:3) {
        stop("The action value must be an integer between 0 - 2")
      }

      conn <- dbGetConn(dbInfo)

      if (sqliteIsTransacting(conn)) {
        endTransaction <- F
      } else {
        dbBegin(conn)
        endTransaction <- T
      }

      q <- dbExecute(
        conn,
        sprintf(
          "INSERT INTO updateData (\"timestamp\", \"action\") VALUES (datetime('now', 'localtime'), %i)",
          action
        )
      )

      if (endTransaction) {
        dbCommit(conn)
        if (!attr(conn, "existing")) {
          dbDisconnect(conn)
        }
      }
    },
    error = function(e) {
      # If an error occurs, rollback the current transaction
      dbRollback(conn)
      if (!attr(conn, "existing")) {
        dbDisconnect(conn)
      }
      stop(e)
    }
  )
}

#' Add authors to the database
#'
#' @param authorPublications List of data frames geneated by ncbi_publicationDetails()
#' @param flagUpdate Default= T, set an update flag in the DB so the app will refresh once completed
#' @param dbInfo (optional if dbSetup() has been run)
#'  Path to the ColabNet database or existing connection
#'
#' @import RSQLite
#' @import dplyr
#'
#' @return Data is inserted into the DB returning a list the author's aritcles (arID and PMID)
#' @export
#'
dbAddAuthorPublications <- function(
  authorPublications,
  matchOnFirst = F,
  flagUpdate = T,
  dbInfo
) {
  tryCatch(
    {
      if (nrow(authorPublications$articles) == 0) {
        return(data.frame(
          arID = integer(),
          PMID = integer(),
          status = character()
        ))
      }

      conn <- dbGetConn(dbInfo)

      if (sqliteIsTransacting(conn)) {
        endTransaction <- F
      } else {
        dbBegin(conn)
        endTransaction <- T
      }

      ### ADD ARTICLES
      articles <- authorPublications$articles

      # Check which articles are already in the database
      existing <- tbl(conn, "article") |>
        filter(PMID %in% local(articles$PMID)) |>
        select(arID, PMID) |>
        collect() |>
        mutate(status = "existing")
      new <- articles |> filter(!PMID %in% existing$PMID)

      if (nrow(new) > 0) {
        new <- dbGetQuery(
          conn,
          "INSERT INTO article(PMID,title,journal,year,month,day)
        VALUES (?,?,?,?,?,?) RETURNING arID, PMID",
          params = list(
            new$PMID,
            new$title,
            new$journal,
            new$year,
            new$month,
            new$day
          )
        ) |>
          mutate(status = "new")
      } else {
        new <- data.frame()
      }

      arInfo <- bind_rows(new, existing)

      # Stop if no new articles were found
      if (all(arInfo$status == "existing")) {
        # Check if the author was already marked as one of interest
        if (matchOnFirst) {
          auID <- tbl(conn, "authorName") |>
            filter(
              lastName %in% local(authorPublications$author$lastName),
              firstName %in% local(authorPublications$author$firstName)
            ) |>
            pull(auID) |>
            unique()
        } else {
          auID <- tbl(conn, "authorName") |>
            filter(
              lastName %in% local(authorPublications$author$lastName),
              initials %in% local(authorPublications$author$initials)
            ) |>
            pull(auID) |>
            unique()
        }

        if (length(auID) != 1) {
          dbRollback(conn)
          if (!attr(conn, "existing")) {
            dbDisconnect(conn)
          }
          stop(ifelse(
            length(auID) > 1,
            "Ambiguous author of interest",
            "No match on author first and last name"
          ))
        }

        q <- dbExecute(
          conn,
          "UPDATE author SET authorOfInterest = 1 WHERE auID = ?",
          params = list(auID)
        )

        q <- dbExecute(
          conn,
          "INSERT INTO updateData (\"timestamp\", \"action\") VALUES (datetime('now', 'localtime'), 1)"
        )

        if (endTransaction) {
          dbCommit(conn)
          if (!attr(conn, "existing")) {
            dbDisconnect(conn)
          }
        }

        return(arInfo %>% mutate(auID = {{ auID }}))
      }

      # Only continue with new article data from authorPublications
      authorPublications <- filter_PMID(authorPublications, PMIDs = new$PMID)

      ### ADD (CO)AUTHOR INFO
      auInfo <- dbAddAuthors(authorPublications$coAuthors, dbInfo = conn)

      # Set authorOfInterest to TRUE to distinguish from co-authors
      if (matchOnFirst) {
        auID <- auInfo |>
          filter(
            lastName %in% authorPublications$author$lastName,
            firstName %in% authorPublications$author$firstName
          ) |>
          pull(auID) |>
          unique()
      } else {
        auID <- auInfo |>
          filter(
            lastName %in% authorPublications$author$lastName,
            initials %in% authorPublications$author$initials
          ) |>
          pull(auID) |>
          unique()
      }

      if (length(auID) != 1) {
        dbRollback(conn)
        if (!attr(conn, "existing")) {
          dbDisconnect(conn)
        }
        stop(ifelse(
          length(auID) > 1,
          "Ambiguous author of interest",
          "No match on author first and last name"
        ))
      }

      q <- dbExecute(
        conn,
        "UPDATE author SET authorOfInterest = 1 WHERE auID = ?",
        params = list(auID)
      )

      # ADD AFFILIATIONS
      affiliations <- authorPublications$affiliations

      existing <- tbl(conn, "affiliation") |>
        filter(affiliation %in% local(unique(affiliations$affiliation))) |>
        collect()
      new <- affiliations |>
        select(affiliation) |>
        distinct() |>
        filter(!affiliation %in% existing$affiliation)
      if (nrow(new) > 0) {
        new <- dbGetQuery(
          conn,
          "INSERT INTO affiliation(affiliation)
        VALUES (?) RETURNING *",
          params = list(new$affiliation)
        )
      }

      afInfo <- bind_rows(new, existing)

      # ADD ARTICLE (CO)AUTHOR INFO AND AFFILIATIONS
      arAuAf <- authorPublications$coAuthors |>
        left_join(
          auInfo,
          by = c("lastName", "firstName", "initials", "collectiveName"),
          na_matches = "na"
        ) |>
        left_join(
          authorPublications$affiliations,
          by = c("PMID", "authorOrder")
        ) |>
        left_join(afInfo, by = "affiliation") |>
        left_join(arInfo, by = "PMID")

      # Filter out articles that are already in the database (via other author of interest)
      coAuthors <- arAuAf |>
        select(arID, auID, authorOrder, anID) |>
        distinct()
      q <- dbExecute(
        conn,
        "INSERT INTO coAuthor(arID, auID, authorOrder, anID) VALUES(?,?,?,?)",
        params = list(
          coAuthors$arID,
          coAuthors$auID,
          coAuthors$authorOrder,
          coAuthors$anID
        )
      )

      # Sometimes affiliations are not provided so remove the empty ones
      affiliations <- arAuAf |>
        select(arID, auID, afID) |>
        distinct() |>
        filter(!is.na(afID))
      q <- dbExecute(
        conn,
        "INSERT INTO author_affiliation(arID, auID, afID) VALUES(?,?,?)",
        params = list(affiliations$arID, affiliations$auID, affiliations$afID)
      )

      # ADD MESH INFO
      # First make sure the MeSH tree is complete for any new terms
      meshDescriptors <- authorPublications$meshDescriptors |>
        left_join(arInfo, by = "PMID") |>
        filter(status == "new")

      if (nrow(meshDescriptors) > 0) {
        meshui <- unique(meshDescriptors$DescriptorUI)

        # The check tags male (D008297) and female (D005260) will be ignored as they
        #  are not part of the MeSH Tree
        #  https://www.nlm.nih.gov/tsd/cataloging/MeSH_CatPractices.html
        meshui <- meshui[!meshui %in% c("D008297", "D005260")]

        # Add nymissing MeSH terms / Tree branches to the database
        if (length(meshui) > 0) {
          result <- dbAddMesh(meshui, "meshui", dbInfo = conn)
        }

        # Remove any mesh descriptors that were not added to the database
        notAdded <- meshui[!meshui %in% result$meshui]

        if (length(notAdded) > 0) {
          warning(
            "The following meshui were not found are are ignored: ",
            paste(notAdded, collapse = ", ")
          )
        }

        # Insert new meshUI from papers
        meshArticle <- meshDescriptors |>
          select(arID, PMID, DescriptorUI, DescriptorMajor) |>
          filter(!DescriptorUI %in% c(notAdded, "D008297", "D005260")) |>
          distinct() |>
          mutate(DescriptorMajor = ifelse(DescriptorMajor == "Y", 1, 0))

        q <- dbExecute(
          conn,
          "INSERT INTO mesh_article(arID, meshui, descriptorMajor) VALUES(?,?,?)",
          params = list(
            meshArticle$arID,
            meshArticle$DescriptorUI,
            meshArticle$DescriptorMajor
          )
        )
      }

      if (flagUpdate) {
        dbFlagUpdate(1, dbInfo = conn)
      }

      if (endTransaction) {
        dbCommit(conn)
        if (!attr(conn, "existing")) {
          dbDisconnect(conn)
        }
      }

      return(arInfo %>% mutate(auID = {{ auID }}))
    },
    error = function(e) {
      # If an error occurs, rollback the current transaction
      dbRollback(conn)
      if (!attr(conn, "existing")) {
        dbDisconnect(conn)
      }
      stop(e)
    }
  )
}

#' Delete specified articles and any associated authors / author names
#' Useful when an article has been incorrectly associated with an author for
#' example because of name overlap
#'
#' @param arIDs Vector of arIDs to delete (as found in article table)
#' @param dbInfo (optional if dbSetup() has been run)
#'  Path to the ColabNet database or existing connection
#'
#' @import RSQLite
#' @import dplyr
#'
#' @return Dataframe of articles and authors/author names that have been deleted
#' @export
#'
dbDeleteArticle <- function(arIDs, dbInfo) {
  tryCatch(
    {
      s
      conn <- dbGetConn(dbInfo)

      if (sqliteIsTransacting(conn)) {
        endTransaction <- F
      } else {
        dbBegin(conn)
        endTransaction <- T
      }

      # Get all articles and authors to remove
      toRemove <- tbl(conn, "coAuthor") |>
        filter(arID %in% local(arIDs)) |>
        collect()

      # Keep author names that are in other articles not being removed
      toKeep <- tbl(conn, "coAuthor") |>
        filter(anID %in% local(toRemove$anID), !arID %in% local(toRemove$arID))

      toRemove <- toRemove |> filter(!anID %in% toKeep)

      # Authors with action deleteAuthor will be removed completely,
      #  authors with action deleteName only have a specific alternative/incorrect name removed
      removeAuth <- tbl(conn, "authorName") |>
        filter(auID %in% local(toRemove$auID)) |>
        distinct() |>
        collect() |>
        left_join(
          toRemove |> select(auID2 = auID, anID) |> distinct(),
          by = "anID"
        ) |>
        group_by(auID) |>
        mutate(
          action = ifelse(
            any(is.na(auID2)),
            "deleteName",
            "deleteAuthor"
          )
        ) |>
        ungroup() |>
        filter(!is.na(auID2))

      # Delete authors
      delAuID <- removeAuth |>
        filter(action == "deleteAuthor") |>
        pull(auID) |>
        unique()
      q <- dbExecute(
        conn,
        sprintf(
          "DELETE FROM author WHERE auID IN (%s)",
          paste(delAuID, collapse = ",")
        )
      )

      # Delete incorrect names
      delAnID <- removeAuth |>
        filter(action == "deleteName") |>
        pull(anID) |>
        unique()
      q <- dbExecute(
        conn,
        sprintf(
          "DELETE FROM authorName WHERE anID IN (%s)",
          paste(delAnID, collapse = ",")
        )
      )

      # Delete articles
      q <- dbExecute(
        conn,
        sprintf(
          "DELETE FROM article WHERE arID IN (%s)",
          paste(arIDs, collapse = ",")
        )
      )

      if (endTransaction) {
        dbCommit(conn)
        if (!attr(conn, "existing")) {
          dbDisconnect(conn)
        }
      }

      return(removeAuth)
    },
    error = function(e) {
      # If an error occurs, rollback the current transaction
      dbRollback(conn)
      if (!attr(conn, "existing")) {
        dbDisconnect(conn)
      }
      stop(e)
    }
  )
}
